# Spike-sort the Zenodo synthetic dataset using SPC and run benchmarks
# ====================================================================

- input.dhawale.spikes:
    directory: /Volumes/olveczky_lab_holy2/Ashesh/SimulatedData_drift/simulated drift tetrode dataset (full)
    channel_groups: [0]
    ground_truth_output: /Users/anandsrinivasan/dev/fasrc/data/dh_gt.h5
    # start: 0
    # stop: 1000000
    batch_size: 1000

- checkpoint:
    file: /Users/anandsrinivasan/dev/fasrc/data/dh_snippets_spc.h5 # Snippets are stored as a single HDF5 file
    batch_size: 2000 # Batch size determines chunking for next stage; set this to inf to cluster over the whole dataset (warning: N^2 operation)
    batch_overlap: 1000 

- label_old.spc_segfuse:
    t_min: 0.00
    t_max: 0.10
    n_temps: 11
    knn: 11
    cycles: 300
    metric: euclidean
    link_threshold: 0.02 # Threshold for linking two nodes across cluster trees (lower means more links)
    link_sig_s: 0.005 # Sigmoidal scale parameter for link weights
    link_sig_k: 0.03 # Sigmoidal offset parameter for link weights (higher means more links)

- checkpoint:
    file: /Users/anandsrinivasan/dev/fasrc/data/dh_linked_snippets_spc.h5 # Clustered snippets are stored as a single HDF5 file
    batch_size: 1000 # Give any batch size here
    batch_overlap: 0 # No overlap required

- finalize

- checkpoint:
    file: /Users/anandsrinivasan/dev/fasrc/data/dh_labeled_snippets_spc.h5 # Clustered snippets are stored as a single HDF5 file
    batch_size: 1000 # Batch size determines chunking for next stage; since this is the last step, this has no effect.
    batch_overlap: 0 

- benchmark.extrinsic:
    output_file: /Users/anandsrinivasan/dev/fasrc/benchmarks/dh_spc.json
    method_name: spc-segfuse # Given name for your spike-sorting method
    dataset_name: Dhawale # Given name for your dataset (used for comparison)
    ground_truth_data: /Users/anandsrinivasan/dev/fasrc/data/dh_gt.h5
    max_dt_ground_truth: 4 # ms
